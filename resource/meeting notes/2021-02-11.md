- the prob is how to efficiently testing a model
- approach is using external invariant to check if a model satisfy these invariant

  - spatial invariant (e.g. medical domain, attention mechanism to highlight)
  - temporal invariant (e.g. video/time series data, e.g. for continuous object detection, etc)

- the contribution is how to introduce invariant to the pipeline
- use the invariant to check if the model contain the task or not
- need to have a pipeline
- need to define what's the input (e.g. model output/predicts, etc)

different with the model assertion paper

- check if the model assertion covers spatial invariant
- if it is generic enough
- to check if the model works/cover the scene/how data connected
- what can be improved
- check previous work in the paper and see what can be improved/if it's efficient, some papers about the current QA work for ML
- how to insert the method into the proposed workflow/pipeline
- try to connect traditional QA experience in coding to ML
- make it a procedure and try to make it as a standard
